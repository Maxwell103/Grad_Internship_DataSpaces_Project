{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color:  #663066; padding: 20px;\">\n",
    "   \n",
    "   \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; justify-content: space-between;\">\n",
    "    <div>\n",
    "        <h1><strong>MIM 2 Data Spaces Graduation Project</strong></h1>\n",
    "        <h4>by Maxwell Ernst - 18/06/2024</h4>\n",
    "    </div>\n",
    "    <div>\n",
    "        <img src=\"fontyslogo.png\" alt=\"Fontys Logo\" style=\"height: 80px; margin-left: 20px;\">\n",
    "\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **MIM2 Process Tutorial**"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "This Jupyter Notebook serves as a tutorial for creating a Minimum Interoperable Mechanism - MIM2 (data models and sharing) for data spaces, using mock data that resembles real-world sensor data. The steps outlined here are designed to be generalizable and can be adapted for various data sources and MIM2 development purposes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1) General Steps for creating a MIM\n",
    "\n",
    "General process for creating a MIM can be outlined in the following steps:\n",
    "\n",
    "1) Read the Data Spaces Summary Document to gain a good understanding of Data Spaces.\n",
    "2) Determine the domain you are working in - Mobility, Smart and Sustainable Cities, and Communities.\n",
    "3) Define the requirements for what needs to be developed to identify which MIM to create, as outlined in the building blocks - Figure 1: Building Blocks taxonomy recommended by OpenDEI and adapted by the DSBA Technical.\n",
    "4) Search for available standards for that MIM from technical and governance standpoints.\n",
    "5) Develop the necessary MIM(s)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![MIMsOverview.png](MIMsOverview.png)\n",
    "\n",
    "Figure 1: Building Blocks taxonomy recommended by OpenDEI and adapted by the DSBA Technical."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Steps for creating MIM2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1) What is MIM2?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "MIM2, or \"Shared Data Models,\" ensures that data sets use the same definitions for key terms, which is crucial for accurate data linking. For instance, if one dataset defines \"children\" as ages 5-15 and another defines them as ages 2-12, merging these datasets would create inaccuracies.\n",
    "\n",
    "Data models are machine-readable definitions of terms, which allow APIs to understand and handle them properly. Consistent data models enable applications to link relevant contextual data with datasets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2) Why are shared data-models important?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A common set of data models creates a shared language, allowing systems to communicate effectively. Well-defined data models help cities to integrate and open up data across different solutions and support various applications. Harmonized data models can be reused, facilitating data sharing and learning among cities."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) EU Policy Context"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Sharing data between different agencies within a city or between cities requires a common way of defining entities. For example, consistent definitions for terms like \"bus\" or \"taxi\" are essential. Without common data models, each agency would need to create their own, making data sharing difficult and inefficient.\n",
    "\n",
    "Common data models support benchmarking and shared learning, reducing the effort required to define data sets."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4) Requirements for Compliance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entities described by data in the ecosystem should use consistent data models based on:\n",
    "\n",
    "- Resource Description Framework (RDF)\n",
    "- Resource Description Framework Schema (RDFS)\n",
    "- Web Ontology Language (OWL)\n",
    "\n",
    "For spatial and spatio-temporal data, consider the provisions of MIM-7 (Places) regarding data encoding."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5) Recommended Specifications"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NGSI-LD compliant data models is the preferred option for smart city aspects. These data models have been defined by organizations and projects, including OASC, FIWARE, GSMA, and the SynchroniCity project. There is ongoing collaboration between OASC, TM Forum, and FIWARE to specify more models through the Smart Data Models initiative: Smart Data Models.\n",
    "\n",
    "Alternatively, existing data models and ontologies can be adapted for use with NGSI-LD by identifying entities, properties, and relationships that can be managed by the NGSI-LD API. Some examples include:\n",
    "\n",
    "- oneM2M base ontology (compatible with SAREF), which provides semantic descriptions of data through metadata\n",
    "- SAREF: Smart Appliances REFerence ontology, with SAREF4Cities focused on smart cities\n",
    "- Core vocabularies of ISA, such as the Core Public Service Vocabulary Application Profile, used for the Single Digital Gateway Regulation\n",
    "- Digital Twin Definition Language (DTDL) developed by Microsoft, based on json-ld, with existing Fiware data models converted to this format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6) Relevant European References and Specifications\n",
    "\n",
    "As part of ongoing work related to MIM2, support for the Smart Data Models Initiative aims to:\n",
    "\n",
    "- Develop guidelines and a catalogue of minimum common data models in different sectors for interoperability\n",
    "- Create harmonized representation formats and semantics for applications to consume and publish data\n",
    "- Develop data models for interoperable and replicable smart solutions across sectors, starting with smart cities and extending to smart agri-food, smart utilities, smart industry, etc.\n",
    "- Establish a methodology to translate between credible initiatives developing data models\n",
    "- Provide guidelines on developing consistent data models\n",
    "- Expand the catalogue of data models agreed upon by OASC cities as common models for use"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) MIM2 Example using mock data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1) Prerequisites"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before following this tutorial, ensure you have the following:\n",
    "\n",
    "- Python 3.x: Download and install Python from https://www.python.org/downloads/.\n",
    "- Jupyter Notebook: Install Jupyter Notebook using pip install jupyter in your terminal.\n",
    "- Pandas library: Install Pandas using pip install pandas in your terminal.\n",
    "- Familiarity with MIM concepts: Basic understanding of MIMs and data spaces is recommended.\n",
    "- datetime, json, and jsonschema (validate, ValadationError) imported as shown in the libraries section"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) Data Source\n",
    "\n",
    "This tutorial utilizes mock data that simulates real-world sensor data. You can replace this with your actual data source during implementation. The mock data will have a similar structure to sensor readings, including:\n",
    "\n",
    "- time_recorded: Timestamp when each observation was recorded in \"YYYY-MM-DD HH:MM\n",
    "\" format.\n",
    "- sensor_identifier: Identifier/name of the sensor that recorded each observation.\n",
    "- temp_celsius: Temperature recorded by each sensor in degrees Celsius.\n",
    "- humidity_percent: Relative humidity recorded at each observation as a percentage.\n",
    "- latitude: Latitude coordinates of the location where each observation was recorded.\n",
    "- longitude: Longitude coordinates of the location where each observation was recorded."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) ETL Process\n",
    "\n",
    "- Extract: In a real scenario, you'd extract data from its source (databases, APIs, etc.). Here, we'll create some mock data to demonstrate the process."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.1) Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from datetime import datetime\n",
    "import json\n",
    "from jsonschema import validate, ValidationError\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5) Extract\n",
    "\n",
    "In this step, the data is extracted depending on the use case, and source data. For this tutorial mock data will be made so no extraction is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_recorded</th>\n",
       "      <th>sensor_identifier</th>\n",
       "      <th>temp_celsius</th>\n",
       "      <th>humidity_percent</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-30 10:00:00</td>\n",
       "      <td>sensor_1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>55</td>\n",
       "      <td>51.452869</td>\n",
       "      <td>5.481549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-30 11:00:00</td>\n",
       "      <td>sensor_2</td>\n",
       "      <td>23.2</td>\n",
       "      <td>60</td>\n",
       "      <td>51.452869</td>\n",
       "      <td>5.481549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-30 12:00:00</td>\n",
       "      <td>sensor_3</td>\n",
       "      <td>21.8</td>\n",
       "      <td>52</td>\n",
       "      <td>51.452869</td>\n",
       "      <td>5.481549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         time_recorded sensor_identifier  temp_celsius  humidity_percent  \\\n",
       "0  2024-05-30 10:00:00          sensor_1          22.5                55   \n",
       "1  2024-05-30 11:00:00          sensor_2          23.2                60   \n",
       "2  2024-05-30 12:00:00          sensor_3          21.8                52   \n",
       "\n",
       "    latitude  longitude  \n",
       "0  51.452869   5.481549  \n",
       "1  51.452869   5.481549  \n",
       "2  51.452869   5.481549  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data = {\n",
    "    \"time_recorded\": [\"2024-05-30 10:00:00\", \"2024-05-30 11:00:00\", \"2024-05-30 12:00:00\"],\n",
    "    \"sensor_identifier\": [\"sensor_1\", \"sensor_2\", \"sensor_3\"],\n",
    "    \"temp_celsius\": [22.5, 23.2, 21.8],\n",
    "    \"humidity_percent\": [55, 60, 52],\n",
    "    \"latitude\": [51.452869111964304, 51.452869111964304, 51.452869111964304],\n",
    "    \"longitude\": [5.481549426062068, 5.481549426062068, 5.481549426062068]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6) Data Model Selection\n",
    "\n",
    "- Choose a standardized data model for representing your data within the MIM2. This tutorial uses Smart Data Models by FIWARE as an example. Select the most appropriate model(s) that aligns with your data content and adheres to MIM2 specifications.\n",
    "\n",
    "- For this example we will follow the WeatherObserved Smart Data Model and transform the data to match the requirements of the Smart Data Model. Below is a link showing each attribute and types that can be used:\n",
    "\n",
    "https://github.com/smart-data-models/dataModel.Weather/blob/master/WeatherObserved/doc/spec.md"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.7) Transform\n",
    "\n",
    "- Transform: This stage involves cleaning, formatting, and manipulating the data to conform to the chosen data model structure. In this example, the data is already relatively clean. However, you might need to handle missing values, convert data types, or create new features depending on your specific data source.\n",
    "\n",
    "- Map the transformed data elements to the corresponding entities and attributes defined in the chosen data model. Here's an example mapping for our mock data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateObserved</th>\n",
       "      <th>id</th>\n",
       "      <th>temperature</th>\n",
       "      <th>relativeHumidity</th>\n",
       "      <th>location</th>\n",
       "      <th>type</th>\n",
       "      <th>dataProvider</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-05-30T10:00:00Z</td>\n",
       "      <td>sensor_1</td>\n",
       "      <td>22.5</td>\n",
       "      <td>55</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [5.4815494260...</td>\n",
       "      <td>WeatherObserved</td>\n",
       "      <td>ExampleProvider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-05-30T11:00:00Z</td>\n",
       "      <td>sensor_2</td>\n",
       "      <td>23.2</td>\n",
       "      <td>60</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [5.4815494260...</td>\n",
       "      <td>WeatherObserved</td>\n",
       "      <td>ExampleProvider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-05-30T12:00:00Z</td>\n",
       "      <td>sensor_3</td>\n",
       "      <td>21.8</td>\n",
       "      <td>52</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [5.4815494260...</td>\n",
       "      <td>WeatherObserved</td>\n",
       "      <td>ExampleProvider</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           dateObserved        id  temperature  relativeHumidity  \\\n",
       "0  2024-05-30T10:00:00Z  sensor_1         22.5                55   \n",
       "1  2024-05-30T11:00:00Z  sensor_2         23.2                60   \n",
       "2  2024-05-30T12:00:00Z  sensor_3         21.8                52   \n",
       "\n",
       "                                            location             type  \\\n",
       "0  {'type': 'Point', 'coordinates': [5.4815494260...  WeatherObserved   \n",
       "1  {'type': 'Point', 'coordinates': [5.4815494260...  WeatherObserved   \n",
       "2  {'type': 'Point', 'coordinates': [5.4815494260...  WeatherObserved   \n",
       "\n",
       "      dataProvider  \n",
       "0  ExampleProvider  \n",
       "1  ExampleProvider  \n",
       "2  ExampleProvider  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Rename columns to match WeatherObserved model\n",
    "df_transformed = df.rename(columns={\n",
    "    \"time_recorded\": \"dateObserved\",\n",
    "    \"sensor_identifier\": \"id\",\n",
    "    \"temp_celsius\": \"temperature\",\n",
    "    \"humidity_percent\": \"relativeHumidity\"\n",
    "})\n",
    "\n",
    "# Convert data types\n",
    "df_transformed[\"dateObserved\"] = pd.to_datetime(df_transformed[\"dateObserved\"]).dt.strftime('%Y-%m-%dT%H:%M:%S') + 'Z'\n",
    "df_transformed[\"location\"] = df_transformed.apply(lambda row: {\"type\": \"Point\", \"coordinates\": [row[\"longitude\"], row[\"latitude\"]]}, axis=1)\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df_transformed = df_transformed.drop(columns=[\"latitude\", \"longitude\"])\n",
    "\n",
    "# Add required static fields\n",
    "df_transformed[\"type\"] = \"WeatherObserved\"\n",
    "df_transformed[\"dataProvider\"] = \"ExampleProvider\"\n",
    "\n",
    "df_transformed\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.8) Load\n",
    "\n",
    "- Load: The transformed data is loaded into a suitable format for further processing. In MIM2 creation, this might involve storing the data in a format compatible with your data space platform.\n",
    "\n",
    "- Next Step is to load the data, in this example we create a CSV and JSON ouput. This data will now be publishable to a Data Space meeitng the requirements of the Smart Data Model by FIWARE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file exported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Export DataFrame to CSV file\n",
    "df_transformed.to_csv('weather_observation_data.csv', index=False)\n",
    "\n",
    "print(\"CSV file exported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file exported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Export DataFrame to JSON file\n",
    "df_transformed.to_json('weather_observation_data.json', orient='records')\n",
    "\n",
    "print(\"JSON file exported successfully.\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.9) JSON Validation Test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step is to create a JSON schema and test the input data with the schema as shown below.\n",
    "\n",
    "JSON Schema of data model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"$schema\": \"http://json-schema.org/draft-07/schema#\",\n",
    "    \"title\": \"Weather Observation Data\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"dateObserved\": {\n",
    "            \"type\": \"string\",\n",
    "            \"format\": \"date-time\"\n",
    "        },\n",
    "        \"id\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"temperature\": {\n",
    "            \"type\": \"number\"\n",
    "        },\n",
    "        \"relativeHumidity\": {\n",
    "            \"type\": \"integer\"\n",
    "        },\n",
    "        \"location\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"type\": {\n",
    "                    \"type\": \"string\"\n",
    "                },\n",
    "                \"coordinates\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"number\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"type\", \"coordinates\"]\n",
    "        },\n",
    "        \"type\": {\n",
    "            \"type\": \"string\"\n",
    "        },\n",
    "        \"dataProvider\": {\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"dateObserved\", \"id\", \"temperature\", \"relativeHumidity\", \"location\", \"type\", \"dataProvider\"]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JSON input of the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_json = {\n",
    "    \"dateObserved\": \"2024-05-30T10:00:00Z\",\n",
    "    \"id\": \"sensor_1\",\n",
    "    \"temperature\": 22.5,\n",
    "    \"relativeHumidity\": 55,\n",
    "    \"location\": {\n",
    "        \"type\": \"Point\",\n",
    "        \"coordinates\": [5.481549426062068, 51.452869111964304]\n",
    "    },\n",
    "    \"type\": \"WeatherObserved\",\n",
    "    \"dataProvider\": \"ExampleProvider\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validate the input JSON against the schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input JSON is valid.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "try:\n",
    "    validate(instance=input_json, schema=schema)\n",
    "    print(\"Input JSON is valid.\")\n",
    "except ValidationError as e:\n",
    "    print(f\"Input JSON is invalid: {e.message}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the validation test has passed and the input matches the schema."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.10) Conclusion\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial has guided through the process of creating a Minimum Interoperable Mechanism (MIM2) for data spaces, specifically focusing on the development of shared data models using mock sensor data. The key steps covered include:\n",
    "\n",
    "- Data Understanding and Preparation: We explored the importance of standardized data models and their role in enabling interoperability across different systems and applications within data spaces.\n",
    "\n",
    "**Implementation Steps:**\n",
    "\n",
    "- We started with mock data resembling real-world sensor readings, including temperature, humidity, and spatial coordinates.\n",
    "- Through the Extract, Transform, Load (ETL) process, we cleaned and formatted the data to conform to the WeatherObserved Smart Data Model.\n",
    "- The transformed data was then exported to both CSV and JSON formats, suitable for publication in a data space.\n",
    "- We validated the JSON data against a predefined schema to ensure compliance with the WeatherObserved data model.\n",
    "\n",
    "**Next Steps:**\n",
    "\n",
    "- For future projects, consider integrating real data sources and adapting the tutorial steps to more complex MIM2 requirements.\n",
    "- Explore additional Smart Data Models and adapt them to specific domain needs.\n",
    "- Further investigate the integration of data models with platforms supporting NGSI-LD and other interoperable frameworks.\n",
    "\n",
    "This tutorial provides a foundational understanding of MIM2 development, demonstrating practical steps for transforming and validating data using standardized data models. It encourages further exploration into data interoperability and smart city solutions.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bibliography/Sources"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FIWARE Smart Data Models. Available at: https://github.com/smart-data-models\n",
    "- Smart Data Models website : https://smartdatamodels.org/\n",
    "- MIMs Plus Report: https://living-in.eu/group/7/commitments/mims-plus-version-5-final\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "def90640ecba0995ed388cef70a65c425c38760ebd7e0c41ef2cfea34d9268c7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
